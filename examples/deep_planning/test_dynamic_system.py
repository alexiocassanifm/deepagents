#!/usr/bin/env python3
"""
ðŸ§ª FERRARI SYSTEM TEST - Complete Dynamic Deep Planning Agent Testing

This script tests the complete dynamic system to ensure the refactoring
is 100% functional and the Ferrari is running at full speed!

Tests:
1. Dynamic Agent Factory creation
2. Phase-specific agent generation  
3. Context-aware TODO generation
4. Tool filtering per phase
5. Phase validation and transitions
6. Complete workflow simulation

Run with: python test_dynamic_system.py
"""

import sys
import os
from typing import Dict, Any, List
from dataclasses import dataclass

# Add the current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from dynamic_agent_factory import (
        DynamicAgentFactory,
        create_dynamic_agent_factory,
        validate_factory_setup
    )
    from prompt_config import PhaseType, get_phase_config
    from prompt_templates import (
        generate_phase_todos,
        generate_phase_context,
        get_tool_context
    )
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("ðŸ”§ Make sure you're running from the deep_planning directory")
    sys.exit(1)


@dataclass
class MockTool:
    """Mock tool for testing."""
    name: str
    description: str


# ============================================================================
# TEST DATA SETUP
# ============================================================================

def create_test_tools() -> List[MockTool]:
    """Create mock tools for testing."""
    return [
        MockTool("General_list_projects", "List available projects"),
        MockTool("Studio_list_needs", "List project needs"),
        MockTool("Code_find_relevant_code_snippets", "Find code snippets"),
        MockTool("Code_get_file", "Get file content"),
        MockTool("write_file", "Write file"),
        MockTool("read_file", "Read file"),
        MockTool("edit_file", "Edit file"),
        MockTool("review_plan", "Review implementation plan"),
        MockTool("write_todos", "Write todo list")
    ]


def create_test_states() -> Dict[str, Dict[str, Any]]:
    """Create various test states for different scenarios."""
    return {
        "ecommerce_investigation": {
            "project_id": "ecommerce_platform",
            "project_type": "web_application",
            "project_domain": "e-commerce",
            "project_name": "ShopFast Platform",
            "current_phase": "investigation",
            "completed_phases": [],
            "context_summary": "Initial investigation of e-commerce platform",
            "focus_area": "payment processing",
            "files": {}
        },
        
        "healthcare_discussion": {
            "project_id": "patient_portal",
            "project_type": "healthcare_app",
            "project_domain": "healthcare",
            "project_name": "MedConnect Portal",
            "current_phase": "discussion",
            "completed_phases": ["investigation"],
            "context_summary": "Patient portal requirements clarification",
            "focus_area": "patient data security",
            "knowledge_gaps": ["HIPAA compliance", "user authentication"],
            "files": {
                "investigation_findings.md": "Detailed investigation results...",
                "project_context.md": "Project context and background..."
            }
        },
        
        "fintech_planning": {
            "project_id": "trading_platform",
            "project_type": "financial_app",
            "project_domain": "fintech",
            "project_name": "TradeMax Platform",
            "current_phase": "planning",
            "completed_phases": ["investigation", "discussion"],
            "context_summary": "Trading platform implementation planning",
            "focus_area": "real-time data processing",
            "architecture_type": "microservices",
            "files": {
                "investigation_findings.md": "Trading platform analysis...",
                "clarification_questions.md": "Questions about requirements...",
                "user_responses.md": "User responses to clarifications...",
                "requirements_clarified.md": "Final clarified requirements..."
            }
        }
    }


# ============================================================================
# TEST FUNCTIONS
# ============================================================================

def test_dynamic_factory_creation() -> bool:
    """Test 1: Dynamic Agent Factory Creation"""
    print("\nðŸ§ª TEST 1: Dynamic Agent Factory Creation")
    
    try:
        tools = create_test_tools()
        factory = create_dynamic_agent_factory(tools)
        
        # Validate factory setup
        validation_report = validate_factory_setup(factory)
        
        if validation_report['factory_valid']:
            print(f"  âœ… Factory created successfully")
            print(f"  âœ… Agents created: {validation_report['created_agents']}")
            print(f"  âœ… Phase coverage: {validation_report['phase_coverage']}")
            return True
        else:
            print(f"  âŒ Factory validation failed: {validation_report['errors']}")
            return False
            
    except Exception as e:
        print(f"  âŒ Factory creation failed: {e}")
        return False


def test_phase_specific_agents() -> bool:
    """Test 2: Phase-Specific Agent Generation"""
    print("\nðŸ§ª TEST 2: Phase-Specific Agent Generation")
    
    try:
        tools = create_test_tools()
        factory = create_dynamic_agent_factory(tools)
        test_states = create_test_states()
        
        success_count = 0
        total_tests = 0
        
        for state_name, state in test_states.items():
            current_phase = state["current_phase"]
            print(f"\n  ðŸ” Testing {state_name} ({current_phase} phase)")
            
            try:
                phase_type = PhaseType(current_phase)
                agent_config = factory.create_agent_from_phase(phase_type, state)
                
                # Validate agent config has required components
                required_keys = ["name", "prompt", "tools", "dynamic_todos", "phase_context"]
                missing_keys = [key for key in required_keys if key not in agent_config]
                
                if not missing_keys:
                    print(f"    âœ… Agent created with all required components")
                    print(f"    âœ… Dynamic TODOs: {len(agent_config['dynamic_todos'])}")
                    print(f"    âœ… Filtered tools: {len(agent_config['tools'])}")
                    print(f"    âœ… Context-aware: {agent_config['name']} for {state['project_name']}")
                    success_count += 1
                else:
                    print(f"    âŒ Missing components: {missing_keys}")
                
                total_tests += 1
                
            except Exception as e:
                print(f"    âŒ Agent creation failed: {e}")
                total_tests += 1
        
        success_rate = (success_count / total_tests * 100) if total_tests > 0 else 0
        print(f"\n  ðŸ“Š Success rate: {success_count}/{total_tests} ({success_rate:.1f}%)")
        
        return success_rate >= 80  # 80% success rate threshold
        
    except Exception as e:
        print(f"  âŒ Phase-specific agent test failed: {e}")
        return False


def test_context_aware_generation() -> bool:
    """Test 3: Context-Aware TODO and Prompt Generation"""
    print("\nðŸ§ª TEST 3: Context-Aware TODO and Prompt Generation")
    
    try:
        test_states = create_test_states()
        
        # Test that different project contexts generate different TODOs
        ecommerce_state = test_states["ecommerce_investigation"]
        healthcare_state = test_states["healthcare_discussion"]
        
        # Generate TODOs for different contexts
        ecommerce_context = generate_phase_context("investigation", ecommerce_state)
        healthcare_context = generate_phase_context("discussion", healthcare_state)
        
        ecommerce_todos = generate_phase_todos("investigation", ecommerce_context)
        healthcare_todos = generate_phase_todos("discussion", healthcare_context)
        
        # Check that TODOs are actually different and context-specific
        ecommerce_content = " ".join([todo["content"] for todo in ecommerce_todos])
        healthcare_content = " ".join([todo["content"] for todo in healthcare_todos])
        
        context_specific = True
        
        # Check for project-specific terms
        if "e-commerce" in ecommerce_content.lower() or "payment" in ecommerce_content.lower():
            print("    âœ… E-commerce TODOs contain project-specific context")
        else:
            print("    âŒ E-commerce TODOs lack project context")
            context_specific = False
        
        if "healthcare" in healthcare_content.lower() or "patient" in healthcare_content.lower():
            print("    âœ… Healthcare TODOs contain project-specific context")
        else:
            print("    âŒ Healthcare TODOs lack project context")
            context_specific = False
        
        # Check that TODOs are actually different
        if ecommerce_content != healthcare_content:
            print("    âœ… Different projects generate different TODOs")
        else:
            print("    âŒ TODOs are identical across different projects")
            context_specific = False
        
        # Test tool context generation
        tools = create_test_tools()
        investigation_tools = get_tool_context("investigation", tools)
        discussion_tools = get_tool_context("discussion", tools)
        
        if investigation_tools["tool_count"] != discussion_tools["tool_count"]:
            print("    âœ… Different phases filter tools differently")
        else:
            print("    âš ï¸ Tool filtering may not be working optimally")
        
        return context_specific
        
    except Exception as e:
        print(f"  âŒ Context-aware generation test failed: {e}")
        return False


def test_phase_validation() -> bool:
    """Test 4: Phase Validation and Transitions"""
    print("\nðŸ§ª TEST 4: Phase Validation and Transitions")
    
    try:
        tools = create_test_tools()
        factory = create_dynamic_agent_factory(tools)
        test_states = create_test_states()
        
        validation_tests = [
            ("investigation", test_states["ecommerce_investigation"]),
            ("discussion", test_states["healthcare_discussion"]),
            ("planning", test_states["fintech_planning"])
        ]
        
        success_count = 0
        
        for phase, state in validation_tests:
            print(f"\n  ðŸ” Testing validation for {phase} phase")
            
            try:
                can_transition, next_phase, missing_reqs = factory.validate_phase_transition(phase, state)
                
                # Check that validation provides meaningful results
                if isinstance(can_transition, bool):
                    print(f"    âœ… Validation returned boolean result: {can_transition}")
                    
                    if can_transition and next_phase:
                        print(f"    âœ… Next phase identified: {next_phase}")
                    elif not can_transition and missing_reqs:
                        print(f"    âœ… Missing requirements identified: {len(missing_reqs)} items")
                    
                    success_count += 1
                else:
                    print(f"    âŒ Invalid validation result type")
                    
            except Exception as e:
                print(f"    âŒ Validation failed: {e}")
        
        return success_count == len(validation_tests)
        
    except Exception as e:
        print(f"  âŒ Phase validation test failed: {e}")
        return False


def test_complete_workflow_simulation() -> bool:
    """Test 5: Complete Workflow Simulation"""
    print("\nðŸ§ª TEST 5: Complete Workflow Simulation")
    
    try:
        tools = create_test_tools()
        factory = create_dynamic_agent_factory(tools)
        
        # Start with investigation phase
        initial_state = {
            "project_id": "test_project",
            "project_type": "web_app",
            "project_domain": "testing",
            "project_name": "Test Project",
            "current_phase": "investigation",
            "completed_phases": [],
            "context_summary": "Initial test state",
            "files": {}
        }
        
        phases_tested = []
        current_state = initial_state.copy()
        
        # Simulate progression through phases
        for phase_type in [PhaseType.INVESTIGATION, PhaseType.DISCUSSION, PhaseType.PLANNING]:
            phase_name = phase_type.value
            print(f"\n  ðŸ” Simulating {phase_name} phase")
            
            try:
                # Create agent for current phase
                agent_config = factory.create_agent_from_phase(phase_type, current_state)
                
                if agent_config:
                    print(f"    âœ… {agent_config['name']} created successfully")
                    print(f"    âœ… {len(agent_config['dynamic_todos'])} dynamic TODOs generated")
                    
                    # Simulate phase completion by adding required files
                    phase_config = get_phase_config(phase_type)
                    if phase_config:
                        for output_file in phase_config.required_outputs:
                            current_state["files"][output_file] = f"Simulated content for {output_file}"
                    
                    # Try to validate and advance
                    can_transition, next_phase, missing_reqs = factory.validate_phase_transition(
                        phase_name, current_state
                    )
                    
                    if can_transition:
                        print(f"    âœ… Phase validation passed, can advance to {next_phase}")
                        current_state["current_phase"] = next_phase
                        current_state["completed_phases"].append(phase_name)
                        phases_tested.append(phase_name)
                    else:
                        print(f"    âš ï¸ Phase validation incomplete: {missing_reqs}")
                        phases_tested.append(phase_name)  # Still count as tested
                else:
                    print(f"    âŒ Failed to create agent for {phase_name}")
                    
            except Exception as e:
                print(f"    âŒ Phase simulation failed: {e}")
        
        # Check overall success
        expected_phases = ["investigation", "discussion", "planning"]
        success_rate = len(phases_tested) / len(expected_phases) * 100
        
        print(f"\n  ðŸ“Š Workflow simulation: {len(phases_tested)}/{len(expected_phases)} phases ({success_rate:.1f}%)")
        
        return success_rate >= 80
        
    except Exception as e:
        print(f"  âŒ Complete workflow simulation failed: {e}")
        return False


def run_all_tests() -> bool:
    """Run all tests and return overall success."""
    print("ðŸ FERRARI DYNAMIC SYSTEM - COMPLETE TEST SUITE")
    print("=" * 60)
    
    tests = [
        ("Dynamic Factory Creation", test_dynamic_factory_creation),
        ("Phase-Specific Agents", test_phase_specific_agents),
        ("Context-Aware Generation", test_context_aware_generation),
        ("Phase Validation", test_phase_validation),
        ("Complete Workflow", test_complete_workflow_simulation)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append(result)
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"\n{status} {test_name}")
        except Exception as e:
            print(f"\nðŸ’¥ ERROR {test_name}: {e}")
            results.append(False)
    
    # Overall results
    print("\n" + "=" * 60)
    passed = sum(results)
    total = len(results)
    success_rate = (passed / total * 100) if total > 0 else 0
    
    print(f"ðŸ“Š OVERALL RESULTS: {passed}/{total} tests passed ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("ðŸ ðŸŽï¸ FERRARI IS RUNNING AT FULL SPEED! ðŸŽï¸ ðŸ")
        print("ðŸŽ¯ Dynamic system is fully operational and ready for production!")
    elif success_rate >= 60:
        print("âš ï¸ FERRARI NEEDS TUNING")
        print("ðŸ”§ Some components need adjustment before full deployment")
    else:
        print("ðŸš¨ FERRARI ENGINE PROBLEMS")
        print("ðŸ› ï¸ Major issues detected - system needs debugging")
    
    return success_rate >= 80


if __name__ == "__main__":
    """Run the test suite."""
    try:
        success = run_all_tests()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nðŸ›‘ Tests interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nðŸ’¥ Test suite crashed: {e}")
        sys.exit(1)